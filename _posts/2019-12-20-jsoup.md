---
layout: post
title: Jsoup学习笔记/GDUT教务系统爬虫/爬虫入门教程
date: 2019-12-20
lastDate: 2019-12-24
categories: blog
tags: [Java,学习笔记,持续记录]
description:
editing: true
timedepend: true
musicID: 29122598
---

# 写在前面
1. 本爬虫api的主页[Cerbur的GDUT教务处爬虫](https://gdutday.cerbur.club)   
1. 这是我学习Jsoup进行爬虫的学习笔记，以及自己实现教务系统爬虫的流程，目前此教务系统爬虫repo将持续更新段时间  
1. 内容中可能存在不少的理解错误和逻辑错误欢迎在本[blog repo](https://github.com/Cerbur/Cerbur.github.io)中提issue  
1. 代码不一定是完成正确或或者最优，欢迎fork本[爬虫repo](https://github.com/Cerbur/GDUT-Education-System-Crawler)或者提出issue和pull request  
1. 此爬虫为一个后台api接口，可在[爬虫repo](https://github.com/Cerbur/GDUT-Education-System-Crawler)的README中查看使用方法。 
1. 教程中的代码为不完全正确代码，为提供逻辑所用  
1. [Jsoup的GitHub repo](https://github.com/jhy/jsoup)
1. [Jsoup的文档](https://jsoup.org/)   

# 环境准备  
使用Java11 + spring boot + Jsoup + fastjson，使用maven工程构建，Maven依赖(不包含springboot部分)   

```xml
<dependency>
    <groupId>org.jsoup</groupId>
    <artifactId>jsoup</artifactId>
    <version>1.10.2</version>
    <!-- version 自行挑选 -->
</dependency>
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>fastjson</artifactId>
    <version> 1.2.54</version>
    <!-- version 自行挑选 -->
</dependency>
```  
# Jsoup的使用  
常用的Jsoup库中的常用类有    
```java
    /**
    * Connection接口用于声明一个连接(是连接此时的connet并未真正请求)，其对应的实现类是HttpConnection
    * Jsoup.connect(String url)则用于构建一个内url为此url的HttpConnection
    **/
    Connection con = Jsoup.connect(String url);

    /**
    * Response用于声明连接请求后返回的结果体，其中包括body，cookies等许多重要信息，为了更好处理cookie一类东西，推荐多以此方式获取结果
    **/
    Connection.Response res = con.execute();
    /**
    * Document用于声明一个html doc
    **/
    Document doc = con.get(); //连接以get方式请求返回html页面并以文档形式返回
    doc = Jsoup.parse(String html); //利用Jsoup.parse格式化传入的参数为html格式的string成Document
    doc = Jsoup.parse(res.body()); //Response可以通过body获取到String类型的html
    
    /**
    * Elements/Element 声明元素(集)可以通过Document类下丰富的方法获取元素结点，其方法传值非常像JavaScript中的选择器，所以懂得前端技术会非常好上手，这部分具体使用可查看官方文档
    **/
    Elements elements = doc.select("#mp-itn b a");
```
# 广东工业大学大学/GDUT 教务系统爬虫实战  

## 爬虫的连接    

1. 登录地址: <a>http://authserver.gdut.edu.cn/authserver/login?service=http://jxfw.gdut.edu.cn/new/ssoLogin</a>  
1. 获取课表地址: <a>https://jxfw.gdut.edu.cn/xsgrkbcx!getDataList.action</a>      
1. 获取绩点地址: <a>https://jxfw.gdut.edu.cn/xskccjxx!getDataList.action</a>  
1. 获取考试地址: <a>https://jxfw.gdut.edu.cn/xsksap!getDataList.action</a>  
1. 获取校区地址: <a>https://jxfw.gdut.edu.cn/xjkpxx!xjkpxx.action</a>  

- 其余URL会慢慢贴出   

## 实战  

### 如何登录到教务系统  

1. 登录教务系统后可以发现，网页的cookie中多了一个JSESSIONID，所以要想请求内容必须得先得到此cookie，而通过教务系统登录需要验证码，目前不会验证码的识别，所以通过通常无需验证码的统一身份系统登录来进行获取教务系统的JSESSIONID
1. 通过教务系统登录界面中以统一身份认真登陆可以发现会提供一个带service参数的url，通过此url登录统一身份认证可获取教务系统的cookie  
1. 分析统一身份认证系统的提交表单的form分析提交的参数    

```html
<form id="casLoginForm" method="post">
    <input id="username" name="username" placeholder="用户名" class="auth_input" type="text" value=""/>
    <input id="password" name="password" placeholder="密码" class="auth_input" type="password" value="" autocomplete="off"/>
    <input type="hidden" name="lt" value="fsdfasdfa"/>
    <input type="hidden" name="dllt" value="userNamePasswordLogin"/>
    <input type="hidden" name="execution" value="e2s1"/>
    <input type="hidden" name="_eventId" value="submit"/>
    <input type="hidden" name="rmShown" value="1">
</form>
```
我们可以看到需要出了username(学号)，密码以外还有5个隐藏参数，同时发现网页中多了cookies，所以我们需要先以get方式请求次页面获取到表单中的生成的随机值和cookie，之后再以post去提交此登录url获取到教务系统的cookie  
其实这里可以不用拿cookies选择提起form表单中的action也是可以的，但获取cookie更方便所以使用此方法     

```java
public static final String LOGIN_URL = "http://authserver.gdut.edu.cn/authserver/login?service=http://jxfw.gdut.edu.cn/new/ssoLogin";  
    Map<String, String> getCookie() {
        Connection.Response response = null;
        try {
            //这里构建连接，可以设置很多参数如headers，cookies ua等ua默认为常用吗M/5所以不设置，跟随重定向默认ture，不设置，设置一个超时时间即可
            response = Jsoup.connect(LOGIN_URL)
                .timeout(5000)
                .execute();
        } catch (IOException e) {
            e.printStackTrace();
        }
        //构建html用于解析
        Document doc = null;
        try {
            doc = response.parse();
        } catch (IOException e) {
            e.printStackTrace();
        }
        //查找到登录表单
        Element content = doc.getElementById("casLoginForm");
        //获取到所有input元素
        Elements links = content.getElementsByTag("input");
        //提取type=hidden的元素加入到Map data中
        Map<String, String> data = new HashMap<>(10);
        for (Element link : links) {
            if ("hidden".equals(link.attr("type"))) {
                data.put(link.attr("name"), link.attr("value"));
            }
        }
        data.put("username", username);
        data.put("password", password);
        //构建post请求
        Connection.Response res = null;
        try {
            res = Jsoup.connect(LOGIN_URL)
                    .timeout(5000)
                    //这里添加上一次获取到的cookies
                    .cookies(response.cookies())
                    //这里添加dataMap
                    .data(data)
                    //这里设置请求方式
                    .method(Connection.Method.POST)
                    //因为教务系统ssl有毒，所有我们把安全认证关了
                    .validateTLSCertificates(false)
                    .execute();
        } catch (IOException e) {
            e.printStackTrace();
        }
        //返回
        return res.cookies();
    }
```
好了现在我们以及成功获取到登录教务系统后的cookies了  
### 获取课表爬虫  
我们只需要向url提交一个post请求，并携带对应参数即可
```java
    String url = "https://jxfw.gdut.edu.cn/xsgrkbcx!getDataList.action";
    Map<String, String> dataMap = new HashMap<>(6);
    dataMap.put("zc", "");
    dataMap.put("xnxqdm", "201901");
    dataMap.put("page", "1");
    dataMap.put("rows", "1000");
    dataMap.put("sort", "kxh");
    dataMap.put("order", "asc");
    String res = = Jsoup.connect(url)
                    .cookies(cookies) //这里提交cookies
                    .timeout(outTime)
                    .data(dataMap)
                    .validateTLSCertificates(false)
                    .method(Connection.Method.POST)
                    .execute().body();
```
获取到的返回值是一个诸如这样的格式，而我们需要的数据则是```[]```中间的一部分  
```
{
    "rows"=21,row[]
}
```
我们利用处理一下string就可以获得到一个标准的json格式的课表信息  
```java
    res.substring(res.indexOf("["), res.lastIndexOf("]") + 1);
```
到此爬虫过程完毕，接下来是处理字符串信息和转化的过程
### 使用fastjson序列化需要的参数并转化为List集合
fastjson是阿里巴巴旗下的
```java
public class Schedule {

    @JSONField(name = "kcmc")
    private String courseName;

    @Override
    public String toString() {
        return "Schedule{" +
                "courseName='" + courseName + '\'' +
                '}';
    }

    public String getCourseName() {
        return courseName;
    }

    public void setCourseName(String courseName) {
        this.courseName = courseName;
    }

    public Schedule() {
    }

    public Schedule(String courseName) {
        this.courseName = courseName;
    }
}
```